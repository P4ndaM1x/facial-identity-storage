{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDA5rS9iSWyU",
        "outputId": "9f4d52d7-b297-4254-843c-f2a2ac976402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Cloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 131 (delta 0), reused 1 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (131/131), 1.13 MiB | 7.77 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ],
      "source": [
        "# Install the necessary libraries and clone the repository\n",
        "!pip install ninja\n",
        "!pip install torch torchvision\n",
        "!pip install pillow\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Moving to the stylegan2-ada-pytorch directory\n",
        "import os\n",
        "os.chdir('stylegan2-ada-pytorch')"
      ],
      "metadata": {
        "id": "_4Q4g5IPbjOi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a models folder and download the pretreated model\n",
        "!mkdir models\n",
        "!wget -O models/ffhq.pkl https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciblJjhzblrv",
        "outputId": "27f0e563-4db4-4fcc-dc10-5396053a237c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-03 05:37:17--  https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\n",
            "Resolving nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)... 52.84.18.79, 52.84.18.33, 52.84.18.74, ...\n",
            "Connecting to nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)|52.84.18.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381646055 (364M) [binary/octet-stream]\n",
            "Saving to: ‘models/ffhq.pkl’\n",
            "\n",
            "models/ffhq.pkl     100%[===================>] 363.97M   210MB/s    in 1.7s    \n",
            "\n",
            "2024-06-03 05:37:20 (210 MB/s) - ‘models/ffhq.pkl’ saved [381646055/381646055]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the current directory. All generated images will be saved in this location.\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayICQaXphQfo",
        "outputId": "28776d5e-7768-44cb-ceb2-98a73dab0573"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2-ada-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating images of ten people\n",
        "import torch\n",
        "import pickle\n",
        "import dnnlib\n",
        "import legacy\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "\n",
        "def load_generator(model_path):\n",
        "    # Determine the device to use (GPU if available, else CPU)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load the pretrained model from the given path\n",
        "    with open(model_path, 'rb') as f:\n",
        "        G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
        "    return G\n",
        "\n",
        "def generate_image(generator, seed, truncation_psi=0.5):\n",
        "\n",
        "    # Determine the device to use (GPU if available, else CPU)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "   # Ensuring repeatability of results\n",
        "    torch.manual_seed(seed)\n",
        "    rnd = np.random.RandomState(seed)\n",
        "\n",
        "    # Generate a random latent vector\n",
        "    z = torch.tensor(rnd.randn(1, generator.z_dim), device=device)\n",
        "\n",
        "    # Generate an image using the generator model\n",
        "    img = generator(z, None, truncation_psi=truncation_psi, noise_mode='const')\n",
        "\n",
        "    # Convert the generated image to a format suitable for saving\n",
        "    img = img[0].permute(1, 2, 0).cpu().numpy()\n",
        "    img = (img * 127.5 + 128).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "    # Return the image as a PIL Image object\n",
        "    return PIL.Image.fromarray(img, 'RGB')\n",
        "\n",
        "# Path to the pretrained model\n",
        "model_path = 'models/ffhq.pkl'\n",
        "\n",
        "# Load the generator model\n",
        "generator = load_generator(model_path)\n",
        "\n",
        "# List of seeds to generate different images\n",
        "seeds = [109, 10, 70, 30, 35, 38, 40, 100, 116, 115]\n",
        "\n",
        "# Generate and save images for each seed\n",
        "for seed in seeds:\n",
        "\n",
        "    image = generate_image(generator, seed)\n",
        "    image.save(f'generated_face_{seed}.png')"
      ],
      "metadata": {
        "id": "ooHPHYGQbnv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be36786-8042-4251-cd8f-a287a3bea7c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up PyTorch plugin \"bias_act_plugin\"... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add watermarks informing that images are generated by AI.\n",
        "# It is necessary to add the Arial.ttf file posted in the repository to the /content/stylegan2-ada-pytorch directory.\n",
        "# Click the folder icon on the left and add the file to the folder named stylegan2-ada-pytorch.\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import math\n",
        "\n",
        "def add_watermark(image_path):\n",
        "    # Load the image\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Set the watermark text and its style\n",
        "    watermark_text = \"generated by AI\"\n",
        "    font_size = 120\n",
        "    font = ImageFont.truetype(\"Arial.ttf\", font_size)\n",
        "\n",
        "    # Calculate the diagonal length of the image\n",
        "    diagonal_length = math.sqrt(image.width ** 2 + image.height ** 2)\n",
        "\n",
        "    # Calculate the width and height of the text\n",
        "    text_width, text_height = font.getsize(watermark_text)\n",
        "\n",
        "    # Calculate the new font size based on the diagonal length of the image\n",
        "    new_font_size = int(font_size * diagonal_length / (image.width + image.height))\n",
        "    font = ImageFont.truetype(\"Arial.ttf\", new_font_size)\n",
        "\n",
        "    # Calculate the position of the text along the diagonal of the image\n",
        "    x_offset = (image.width - text_width) // 2\n",
        "    y_offset = (image.height - text_height) // 2\n",
        "\n",
        "    # Create a new layer with transparency\n",
        "    watermark = Image.new(\"RGBA\", (image.width, image.height), (255, 255, 255, 0))\n",
        "    draw = ImageDraw.Draw(watermark)\n",
        "\n",
        "    # Draw the text on the layer and rotate it by 45 degrees\n",
        "    draw.text((x_offset, y_offset), watermark_text, font=font, fill=(255, 255, 255, 128))\n",
        "    watermark_rotated = watermark.rotate(45, expand=True)\n",
        "\n",
        "    # Resize the watermark image to fit the main image\n",
        "    watermark_resized = watermark_rotated.resize(image.size, Image.ANTIALIAS)\n",
        "\n",
        "    # Composite the watermark layer over the original image\n",
        "    watermarked_image = Image.alpha_composite(image.convert(\"RGBA\"), watermark_resized)\n",
        "\n",
        "    # Save the image with the watermark\n",
        "    watermarked_image.save(\"watermarked_\" + image_path)\n",
        "\n",
        "# Adding a watermark to all previously generated images. Images with watermarks are also saved in current directory.\n",
        "\n",
        "seeds = [109, 10, 70, 30, 35, 38, 40, 100, 116, 115]\n",
        "for seed in seeds:\n",
        "    add_watermark(f'generated_face_{seed}.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo-60kJJcmZj",
        "outputId": "72ca7d52-d498-4a91-8e21-326f54050e9b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-0f6977195840>:20: DeprecationWarning: getsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use getbbox or getlength instead.\n",
            "  text_width, text_height = font.getsize(watermark_text)\n",
            "<ipython-input-7-0f6977195840>:39: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  watermark_resized = watermark_rotated.resize(image.size, Image.ANTIALIAS)\n"
          ]
        }
      ]
    }
  ]
}